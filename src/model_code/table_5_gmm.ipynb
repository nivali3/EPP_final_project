{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DellaVigna and Pope, 2018, \"What Motivates Effort? Evidence and Expert Forecasts\", Table 5, GMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Authors:  \n",
    "\n",
    "- Massimiliano Pozzi (Bocconi University, pozzi.massimiliano@studbocconi.it)\n",
    "- Salvatore Nunnari (Bocconi University, salvatore.nunnari@unibocconi.it)\n",
    "\n",
    "#### Description:\n",
    "\n",
    "The code in this Jupyter notebook replicates columns 1 and 3 in Panel A of Table 5 and columns 1 and 4 in Panel B of Table 5. This estimates use minimum distance.\n",
    "\n",
    "This notebook was tested with the following packages versions:\n",
    "- Pozzi:   (Anaconda 4.10.3 on Windows 10 Pro) : python 3.8.3, numpy 1.18.5, pandas 1.0.5, sklearn 1.0\n",
    "- Nunnari: (Anaconda 4.10.1 on macOS 10.15.7): python 3.8.10, numpy 1.20.2, pandas 1.2.4, scikit-learn 0.24.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Cleaning and Data Preparation\n",
    "\n",
    "We import the relevant dataset containing data on the number of buttonpresses in the different treatments and for different piece rates wage that the participants received when completing the task. We then compute the means for the treatments that are used to compute the minimum distance estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the dataset\n",
    "\n",
    "dt = pd.read_stata('../input/mturk_clean_data_short.dta')\n",
    "\n",
    "# compute the rounded empirical moments in the different treatments\n",
    "\n",
    "emp_moments = np.array(np.round(dt.groupby(\"treatment\").mean(\"buttonpresses\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up the bootstrap procedure for the standard errors. The cell below creates 'number' new samples and computes the mean for the relevant treatments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50% done\n",
      "100% done\n"
     ]
    }
   ],
   "source": [
    "# Treatments are as follows:\n",
    "# 1.1: benchmark specification with piece rate of 0.01 \n",
    "# 1.2: benchmark specification with piece rate of 0.10 \n",
    "# 1.3: benchmark specification with piece rate of 0.00 \n",
    "# 3.1: social preferences (charity) with piece rate of 0.01 \n",
    "# 3.2: social preferences (charity) with piece rate of 0.10 \n",
    "# 10 : social preferences (gift exchange) bonus of 40 cents (independently of nr buttonpresses)\n",
    "# 4.1: time discounting with extra 0.01 paid two weeks later\n",
    "# 4.2: time discounting with extra 0.01 paid four weeks later\n",
    "\n",
    "# resample is a useful command from the sklearn library that samples with replacement our data.\n",
    "# We first get a smaller dataframe containing only observations for a specific treatment, we then resample the observations and\n",
    "# compute the rounded mean of buttonpresses, save the result and then pass onto the next treatment. we do this for 'number' times.\n",
    "\n",
    "def bootstrap(dataset, number):\n",
    "    \n",
    "    # define the vector containing the treatments (used for the loop) and the vectors that will store the mean buttonpresses in our 1000 new samples. \n",
    "    # E11 is a 1xnumber vector that will contain the average buttonpresses in each of our 'number' samples for treatment 1.1 etc.\n",
    "\n",
    "    treatment = ['1.1', '1.2', '1.3', '3.1', '3.2', '10', '4.1', '4.2']\n",
    "    E11, E12, E13, E31, E32, E10, E41, E42 = [], [], [], [], [], [], [], []\n",
    "\n",
    "    for i in range(1, number+1):     # we want 'number' new samples\n",
    "        for treat in treatment:      # we want to compute the mean for all relevant treatments\n",
    "            db = dataset[dataset.treatment==treat] # keep only observations for treatment 'treat'\n",
    "            bootsample = resample(db['buttonpresses'],replace=True,) # resample the dataset\n",
    "            if treat == '1.1': E11.append(np.round(np.mean(bootsample)))\n",
    "            if treat == '1.2': E12.append(np.round(np.mean(bootsample)))\n",
    "            if treat == '1.3': E13.append(np.round(np.mean(bootsample)))\n",
    "            if treat == '3.1': E31.append(np.round(np.mean(bootsample)))\n",
    "            if treat == '3.2': E32.append(np.round(np.mean(bootsample)))\n",
    "            if treat == '10' : E10.append(np.round(np.mean(bootsample)))\n",
    "            if treat == '4.1': E41.append(np.round(np.mean(bootsample)))\n",
    "            if treat == '4.2': E42.append(np.round(np.mean(bootsample)))\n",
    "                \n",
    "        if i == 500:  print('50% done')\n",
    "        if i == 1000: print('100% done')\n",
    "            \n",
    "    return E11, E12, E13, E31, E32, E10, E41, E42\n",
    "\n",
    "bt = bootstrap(dt,2000)\n",
    "E11, E12, E13, E31, E32, E10, E41, E42 = bt[0], bt[1], bt[2], bt[3], bt[4], bt[5], bt[6], bt[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model and Estimation Technique (Section 2 in the Paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is one of costly effort, where an agent needs to choose the optimal effort (in this case the number of buttons pressed in a 10 minute session) to solve a simple tradeoff problem between disutility of effort and consumption utility derived from the consequent payment. On top of this simple problem the authors use 18 different treatments to examine the effects of standard monetary incentives, behavioral factors like social preferences and reference dependence and non-monetary incentives. We briefly examine here the benchmark model and the solutions for the treatments used for the minimum distance estimates we compute.\n",
    "\n",
    "The model for treatment 1.1, 1.2 and 1.3 can be written as follows:\n",
    "\n",
    "$$ \\max_{e\\geq0} \\;\\; (s+p)e-c(e) $$\n",
    "\n",
    "Where e is the number of buttons pressed, p is the piece-rate that varies across treatments, s a parameter that captures intrinsic motivation and c(e) is a convex cost function, either of power or exponential form:\n",
    "\n",
    "$$ c(e)=\\frac{ke^{1+\\gamma}}{1+\\gamma} \\qquad \\qquad c(e)=\\frac{kexp(\\gamma e)}{\\gamma}$$\n",
    "\n",
    "given this problem an optimal interior solution can be found trough the first order condition:\n",
    "\n",
    "$$ e^*= c^{'-1}(s+p) \\qquad \\qquad e^*= \\left(\\frac{s+p}{k}\\right)^{\\frac{1}{\\gamma}} \\qquad \\qquad e^*= \\frac{1}{\\gamma}\\left(\\frac{s+p}{k}\\right) $$\n",
    "\n",
    "where the first equation uses a generic cost function, the second one a power cost function and the last one an exponential cost function. The parameters to estimate are three: s, k and &gamma;. Given the fact that we have three different treatments with three different piece-rate we can estimate the parameters by imposing the theoretical moments found trought the first order condition to be equal to the empirical moments. This will lead to a system of three equations in three unknowns that is exactly identified. Once we have an estimate for s, k and &gamma; we use these to find the estimates for the parameters in the other treatments.\n",
    "\n",
    "For the social preferences (charitable giving) treatments 3.1, 3.2 the optimal effort is:\n",
    "\n",
    "$$ e^*= c^{'-1}(s+ \\alpha p_{CH}+a*0.01) $$\n",
    "\n",
    "where &alpha; is a parameter that multiplies the return to charity and a is a \"warm glow\" parameter, so that an individual cares about giving to charity but does not pay attention to the actual return. We have two different charity piece rate, so two different empirical moments that can be used to identify &alpha; and a.\n",
    "\n",
    "For the social preferences (gift exchange) treatment 10 the optimal effort is:\n",
    "\n",
    "$$ e^*= c^{'-1}(s+ \\Delta s_{GE}) $$\n",
    "\n",
    "where &Delta;s<sub>GE</sub> represents a possible increase of intrinsic motivation s because of the gift, reflecting positive reciprocity towards the employer.\n",
    "\n",
    "Finally we have the time preferences treatments 4.1, 4.2 whose optimal effort is:\n",
    "\n",
    "$$ e^*= c^{'-1}(s+ \\beta \\delta^t p) $$\n",
    "\n",
    "where beta is the present bias parameter and delta is the standard time discounting. In this case we have two different t: two weeks and four weeks that allows us to identify the two parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to estimate the parameters using minimum distance. \n",
    "# There are two specifications: exponential cost function and power cost function\n",
    "# The parameters are found by imposing the theoretical means found from the agent's problem being equal to the empirical mean found in the data.\n",
    "# E11 up to E42 are the relevant empirical moments\n",
    "# specification can either be 'Exp' or 'Power'\n",
    "# P is a vector containing the different piece-rates \n",
    "# To simplify the computations the authors take the log of the variables to estimate gamma k and s.\n",
    "\n",
    "def mindisest(E11,E12,E13,E31,E32,E10,E41,E42,specification):\n",
    "    \n",
    "    P=[0,0.01,0.1,]\n",
    "    \n",
    "    if specification == 'Exp':\n",
    "        \n",
    "        log_k = (np.log(P[2]) - np.log(P[1])*(E12)/(E11))/(1 - (E12)/(E11))\n",
    "        log_gamma = np.log((np.log(P[1]) - log_k)/(E11))\n",
    "        log_s = np.exp(log_gamma)*(E13) + log_k\n",
    "        \n",
    "    if specification == 'Power':\n",
    "        \n",
    "        log_k = (np.log(P[2]) - np.log(P[1])*np.log(E12)/np.log(E11))/(1 - np.log(E12)/np.log(E11))\n",
    "        log_gamma = np.log((np.log(P[1]) - log_k)/np.log(E11))\n",
    "        log_s = np.exp(log_gamma)*np.log(E13) + log_k\n",
    "        \n",
    "    k = np.exp(log_k)       # estimate for k\n",
    "    g = np.exp(log_gamma)   # estimate for gamma\n",
    "    s = np.exp(log_s)       # estimate for s\n",
    "    \n",
    "    if specification == 'Exp':\n",
    "        \n",
    "        EG31, EG32, EG10, EG41, EG42 = np.exp(E31*g), np.exp(E32*g), np.exp(E10*g), np.exp(E41*g), np.exp(E42*g)\n",
    "        alpha = 100/9*k*(EG32-EG31)\n",
    "        a = 100*k*EG31-100*s-alpha\n",
    "        s_ge = k*EG10 - s\n",
    "        delta = np.sqrt((k*EG42-s)/(k*EG41-s))\n",
    "        beta  = 100*(k*EG41-s)/(delta**2)\n",
    "        \n",
    "    if specification == 'Power':\n",
    "        \n",
    "        alpha = 100/9*k*( E32**g-E31**g )\n",
    "        a = 100*k*E31**g-100*s-alpha\n",
    "        s_ge = k*E10**g - s\n",
    "        delta = np.sqrt((k*E42**g-s)/(k*E41**g-s))\n",
    "        beta  = 100*(k*E41**g-s)/(delta**2)\n",
    "        \n",
    "    return k, g, s, alpha, a, s_ge, beta, delta\n",
    "\n",
    "# We vectorize the function so we can use as inputs the vectors containing the means in the different treatments to get the estimatesin our boostrap procedure\n",
    "\n",
    "vmindisest = np.vectorize(mindisest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Estimation\n",
    "\n",
    "### Point Estimates and Standard Errors\n",
    "\n",
    "We now compute the minimum distance estimates for Table 5 and the standard errors via a bootstrap procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 5 minimum distance estimates: columns (1) (3) panel A and columns (1) (4) panel B\n",
    "    \n",
    "Table5Exp = mindisest(emp_moments[0],emp_moments[1],emp_moments[2],emp_moments[6],emp_moments[7],emp_moments[4],emp_moments[8],emp_moments[9],'Exp')\n",
    "Table5Exp = np.array(Table5Exp).flatten()\n",
    "Table5Power = mindisest(emp_moments[0],emp_moments[1],emp_moments[2],emp_moments[6],emp_moments[7],emp_moments[4],emp_moments[8],emp_moments[9],'Power')\n",
    "Table5Power = np.array(Table5Power).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store mean and standard error of estimates for the exponential cost function specification using the Bootstrap procedure\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # This is to avoid showing RuntimeWarning in the notebook regarding overflow. For a couple of cases in our 1000 new samples\n",
    "                                  # we cannot find the results because of overflow. Losing 2-3 observations out of thousands should not change the overall mean\n",
    "                                  # for the parameters\n",
    "\n",
    "estimatesExp = vmindisest(E11,E12,E13,E31,E32,E10,E41,E42,'Exp')\n",
    "k_exp_mean, k_exp_sd = np.nanmean(estimatesExp[0]), np.nanstd(estimatesExp[0])\n",
    "g_exp_mean, g_exp_sd = np.nanmean(estimatesExp[1]), np.nanstd(estimatesExp[1])\n",
    "s_exp_mean, s_exp_sd = np.nanmean(estimatesExp[2]), np.nanstd(estimatesExp[2])\n",
    "alpha_exp_mean, alpha_exp_sd = np.nanmean(estimatesExp[3]), np.nanstd(estimatesExp[3])\n",
    "a_exp_mean, a_exp_sd = np.nanmean(estimatesExp[4]), np.nanstd(estimatesExp[4])\n",
    "s_ge_exp_mean, s_ge_exp_sd = np.nanmean(estimatesExp[5]), np.nanstd(estimatesExp[5])\n",
    "beta_exp_mean, beta_exp_sd = np.nanmean(estimatesExp[6]), np.nanstd(estimatesExp[6])\n",
    "delta_exp_mean, delta_exp_sd = np.nanmean(estimatesExp[7]), np.nanstd(estimatesExp[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store mean and standard error of estimates for the power cost function specification using the Bootstrap procedure\n",
    "\n",
    "estimatesPower = vmindisest(E11,E12,E13,E31,E32,E10,E41,E42,'Power')\n",
    "k_power_mean, k_power_sd = np.nanmean(estimatesPower[0]), np.nanstd(estimatesPower[0])\n",
    "g_power_mean, g_power_sd = np.nanmean(estimatesPower[1]), np.nanstd(estimatesPower[1])\n",
    "s_power_mean, s_power_sd = np.nanmean(estimatesPower[2]), np.nanstd(estimatesPower[2])\n",
    "alpha_power_mean, alpha_power_sd = np.nanmean(estimatesPower[3]), np.nanstd(estimatesPower[3])\n",
    "a_power_mean, a_power_sd = np.nanmean(estimatesPower[4]), np.nanstd(estimatesPower[4])\n",
    "s_ge_power_mean, s_ge_power_sd = np.nanmean(estimatesPower[5]), np.nanstd(estimatesPower[5])\n",
    "beta_power_mean, beta_power_sd = np.nanmean(estimatesPower[6]), np.nanstd(estimatesPower[6])\n",
    "delta_power_mean, delta_power_sd = np.nanmean(estimatesPower[7]), np.nanstd(estimatesPower[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To obtain confidence intervals in panel B table 5. CI are the 2.5% and 97.5% quantiles of the distribution of our\n",
    "# parameters vectors. Since there are 1000 values in each vector, the low/high end of the CI is in position 24 and 974 \n",
    "# of our arrays. We obtain CI only for alpha, a, s_ge, beta, delta as in the paper\n",
    "\n",
    "CI_Exp, CI_Power = [], []\n",
    "for ci in range(3,8):\n",
    "    a  = sorted(estimatesExp[ci])\n",
    "    CI_Exp.append([a[24],a[974]])\n",
    "for ci in range(3,8):\n",
    "    a  = sorted(estimatesPower[ci])\n",
    "    CI_Power.append([a[24],a[974]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two dataframes with our results. Table5Results contains point estimates and standard errors. CIpanelB contains \n",
    "# confidence intervals for the variables alpha, a, s_ge, beta and delta\n",
    "\n",
    "params_name = [\"Level k of cost of effort\", \"Curvature γ of cost function\",\"Intrinsic motivation s\",\"Social preferences α\",\n",
    "                \"Warm glow coefficient a\",\"Gift exchange Δs\", \"Present bias β\",\"(Weekly) discount factor δ\"]\n",
    "               \n",
    "sd_exp   = [k_exp_sd,g_exp_sd,s_exp_sd,alpha_exp_sd,a_exp_sd,s_ge_exp_sd,beta_exp_sd,delta_exp_sd]\n",
    "sd_power = [k_power_sd,g_power_sd,s_power_sd,alpha_power_sd,a_power_sd,s_ge_power_sd,beta_power_sd,delta_power_sd]\n",
    "\n",
    "Table5Results = pd.DataFrame({'Parameters name': params_name,\n",
    "                              'Minimum dist est on average effort Power point estimates': Table5Power,\n",
    "                              'Minimum dist est on average effort Power standard errors': sd_power,\n",
    "                              'Minimum dist est on average effort Exp point estimates': Table5Exp,\n",
    "                              'Minimum dist est on average effort Exp standard errors': sd_exp})\n",
    "CIpanelB = pd.DataFrame({'CI_Exp':CI_Exp, 'CI_Power':CI_Power})\n",
    "\n",
    "# Save the dataframe\n",
    "\n",
    "Table5Results.to_csv('../output/table5GMM_python.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 5: Estimates of behavioural parameters I: Mturkers actual effort. Minimum distance estimates\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters name</th>\n",
       "      <th>Minimum dist est on average effort Power point estimates</th>\n",
       "      <th>Minimum dist est on average effort Power standard errors</th>\n",
       "      <th>Minimum dist est on average effort Exp point estimates</th>\n",
       "      <th>Minimum dist est on average effort Exp standard errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Level k of cost of effort</td>\n",
       "      <td>2.54e-112</td>\n",
       "      <td>3.68e-62</td>\n",
       "      <td>1.27e-16</td>\n",
       "      <td>2.33e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Curvature γ of cost function</td>\n",
       "      <td>33.138</td>\n",
       "      <td>12.065</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Intrinsic motivation s</td>\n",
       "      <td>7.12e-7</td>\n",
       "      <td>1.03e-5</td>\n",
       "      <td>3.32e-6</td>\n",
       "      <td>2.43e-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Social preferences α</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Warm glow coefficient a</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gift exchange Δs</td>\n",
       "      <td>3.26e-6</td>\n",
       "      <td>2.49e-5</td>\n",
       "      <td>8.58e-6</td>\n",
       "      <td>3.92e-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Present bias β</td>\n",
       "      <td>1.17</td>\n",
       "      <td>3.98</td>\n",
       "      <td>1.15</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Weekly) discount factor δ</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Parameters name  \\\n",
       "0     Level k of cost of effort   \n",
       "1  Curvature γ of cost function   \n",
       "2        Intrinsic motivation s   \n",
       "3          Social preferences α   \n",
       "4       Warm glow coefficient a   \n",
       "5              Gift exchange Δs   \n",
       "6                Present bias β   \n",
       "7    (Weekly) discount factor δ   \n",
       "\n",
       "  Minimum dist est on average effort Power point estimates  \\\n",
       "0                                          2.54e-112         \n",
       "1                                             33.138         \n",
       "2                                            7.12e-7         \n",
       "3                                              0.003         \n",
       "4                                              0.125         \n",
       "5                                            3.26e-6         \n",
       "6                                               1.17         \n",
       "7                                               0.75         \n",
       "\n",
       "  Minimum dist est on average effort Power standard errors  \\\n",
       "0                                           3.68e-62         \n",
       "1                                             12.065         \n",
       "2                                            1.03e-5         \n",
       "3                                              0.014         \n",
       "4                                              0.152         \n",
       "5                                            2.49e-5         \n",
       "6                                               3.98         \n",
       "7                                                0.3         \n",
       "\n",
       "  Minimum dist est on average effort Exp point estimates  \\\n",
       "0                                           1.27e-16       \n",
       "1                                              0.016       \n",
       "2                                            3.32e-6       \n",
       "3                                              0.003       \n",
       "4                                              0.143       \n",
       "5                                            8.58e-6       \n",
       "6                                               1.15       \n",
       "7                                               0.76       \n",
       "\n",
       "  Minimum dist est on average effort Exp standard errors  \n",
       "0                                           2.33e-11      \n",
       "1                                              0.006      \n",
       "2                                            2.43e-5      \n",
       "3                                              0.014      \n",
       "4                                              0.156      \n",
       "5                                            3.92e-5      \n",
       "6                                               3.45      \n",
       "7                                               0.29      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "\n",
    "# Formatting the results nicely for the table\n",
    "\n",
    "from decimal import Decimal\n",
    "\n",
    "columns = [Table5Power, sd_power, Table5Exp, sd_exp]\n",
    "vs = []\n",
    "for col in columns:\n",
    "    col = ['{0:.2e}'.format(Decimal(col[0])), round(col[1],3), '{0:.2e}'.format(Decimal(col[2])),\n",
    "           round(col[3],3), round(col[4],3), '{0:.2e}'.format(Decimal(col[5])), round(col[6],2), round(col[7],2)]\n",
    "    vs.append(col)\n",
    "    \n",
    "Table5Results = pd.DataFrame({'Parameters name': params_name,\n",
    "                              'Minimum dist est on average effort Power point estimates': vs[0],\n",
    "                              'Minimum dist est on average effort Power standard errors': vs[1],\n",
    "                              'Minimum dist est on average effort Exp point estimates': vs[2],\n",
    "                              'Minimum dist est on average effort Exp standard errors': vs[3]})\n",
    "    \n",
    "# Standard errors are different since the seed we used for the bootstrap procedure is different from the one used by the authors since \n",
    "# random generation across softwares/languages is not easily replicated (each software uses its own algorithm)\n",
    "\n",
    "from IPython.display import display\n",
    "print('Table 5: Estimates of behavioural parameters I: Mturkers actual effort. Minimum distance estimates')\n",
    "display(Table5Results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
